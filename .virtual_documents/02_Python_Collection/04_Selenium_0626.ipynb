


pwd


from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
import time, urllib.request

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)


URL = "https://korean.visitkorea.or.kr/detail/rem_detail.html?cotid=be3db10c-b642-409c-81cc-c4cdecb5bd8b&temp="
driver = webdriver.Chrome(options=options)
driver.get(URL)
time.sleep(2)


import os
os.getcwd()


f_dir = input('이미지 저장 폴더명 : ')

now = time.localtime()
s = '%04d%02d%02d_%02d%02d%02d'%(now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)
f_name = f_dir +'_' + s

os.makedirs(os.getcwd()+'\\' + f_name)


driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")


html_src = driver.page_source


html_dom = BeautifulSoup(html_src, 'lxml')
html_dom


mylist = html_dom.select('.img_typeBox img')
mylist


img_list = [item['src'] for item in mylist]
img_list


urllib.request.urlretrieve(img_list[0],  'image.jpg')


no = 0
for src in img_list:
    # 다운로드  (주소, 파일이름)
    urllib.request.urlretrieve(src, f'{f_name}\\{no}.jpg')
    no += 1


















































from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import math, time

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)


search = input('검색어:')
cnt = int(input('크롤링 할 건수는 몇건입니까?: '))
page_cnt = math.ceil(cnt / 10)  # 크롤링 할 전체 페이지 수 


URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search
driver = webdriver.Chrome(options=options)
driver.get(URL)
time.sleep(3)


# 여행기사 더보기 클릭
# driver.find_element(By.CSS_SELECTOR, ".more_view").click() 중복주의
driver.find_element(By.CSS_SELECTOR, "#s_recommend > .more_view > a").click()


# 제목 추출
# 왜 길이가 34일까?
result = driver.find_elements(By.CSS_SELECTOR,'.tit a')
len(result)


for i in result:
    print(i.text)


# 더 정확하게 찾아주자
result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')
len(result)


# 한페이지내 콘텐츠별 상세페이지 정보를 추출해보자
# 페이지 로딩시간 고려해서 넉넉히 2~3초 간격을 주자
from bs4 import BeautifulSoup
contents_no = 0

for item in result:
    contents_no += 1
    item.click()
    time.sleep(3)  
    
    print(f'======= [ {contents_no} ]  =======')
    html = driver.page_source

    soup = BeautifulSoup(html, 'lxml')
    title = soup.find(id='topTitle')
    print(title.text)

    driver.back()
    time.sleep(3)

print('==== 완료 ====')
